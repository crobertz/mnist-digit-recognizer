{"cells":[{"metadata":{"_uuid":"2b9425b4-e4d0-4a1b-ae1c-e90cdba745e4","_cell_guid":"ee374fd0-a312-49db-b05f-be5177e4529e","trusted":true},"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"165db1c7-0408-4033-ad2b-33e8e265797a","_cell_guid":"4b6711b6-71bc-459a-a1a1-a2b28cec739b","trusted":true},"cell_type":"code","source":["# import\n","import keras\n","import keras.layers\n","from keras.models import Sequential\n","from keras.optimizers import Adam\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d0f2615-6a54-413a-84a3-1b234aa36a7d","_cell_guid":"0b26eb42-f35f-4980-8f89-eebbd16b7fa0","trusted":true},"cell_type":"code","source":["# load training and test data\n","train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv').to_numpy()\n","test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv').to_numpy()"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b408084a-5289-47f6-b18b-75238f613e4d","_cell_guid":"d23ff9d5-b3ee-4e58-877e-df9affa4e56a","trusted":true},"cell_type":"code","source":["X_train = train[:,1:]\n","Y_train = train[:,0]\n","X_test = test"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dab54ac4-36a8-44ee-9074-f846272c8998","_cell_guid":"fbac26f9-a34c-4068-bf2e-3390a3c52151","trusted":true},"cell_type":"code","source":["# display training data\n","train_index = 23\n","plt.imshow(np.reshape(X_train[train_index], (28, 28)))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["X_train.shape"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# normalize\n","X_train_normalized = X_train / 255.0\n","X_test_normalized = X_test / 255.0"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# reshape\n","X_train_normalized = X_train_normalized.reshape((-1, 28, 28, 1))\n","X_test_normalized = X_test_normalized.reshape((-1, 28, 28, 1))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["X_train_normalized.shape"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Define the plotting function\n","def plot_curve(epochs, hist, list_of_metrics):\n","  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n","  # list_of_metrics should be one of the names shown in:\n","  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics  \n","\n","  plt.figure()\n","  plt.xlabel(\"Epoch\")\n","  plt.ylabel(\"Value\")\n","\n","  for m in list_of_metrics:\n","    x = hist[m]\n","    plt.plot(epochs[1:], x[1:], label=m)\n","\n","  plt.legend()\n","\n","print(\"Loaded the plot_curve function.\")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def create_model(learning_rate):\n","    \"\"\"Create and compile a deep neural net.\"\"\"\n","    # Sequential model\n","    model = keras.models.Sequential()\n","    \n","    # Convolutional layers\n","    model.add(keras.layers.Conv2D(32, 3, activation='relu', padding='same', input_shape=(28,28,1)))\n","    model.add(keras.layers.MaxPooling2D((2,2)))\n","    model.add(keras.layers.Conv2D(32, 3, activation='relu'))\n","    model.add(keras.layers.Conv2D(32, 3, activation='relu'))\n","    model.add(keras.layers.Conv2D(32, 3, activation='relu',))\n","    model.add(keras.layers.MaxPooling2D((2,2)))\n","    \n","    # Flatten\n","    model.add(keras.layers.Flatten())\n","\n","    # Dense layers followed by dropout   \n","    model.add(keras.layers.Dense(units=512, activation='relu')) \n","    model.add(keras.layers.Dropout(rate=0.5))\n","    model.add(keras.layers.Dense(units=256, activation='relu')) \n","    model.add(keras.layers.Dropout(rate=0.5))\n","    \n","\n","    # Output layer with 10 units\n","    model.add(keras.layers.Dense(units=10, activation='softmax'))     \n","\n","    # Compile model with categorical cross-entropy loss\n","    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate),\n","                loss=\"sparse_categorical_crossentropy\",\n","                metrics=['accuracy'])\n","\n","    return model    \n","\n","\n","def train_model(model, train_features, train_label, epochs,\n","                batch_size=None, validation_split=0.1):\n","  \"\"\"Train the model by feeding it data.\"\"\"\n","\n","  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n","                      epochs=epochs, shuffle=True, \n","                      validation_split=validation_split)\n"," \n","  # To track the progression of training, gather a snapshot\n","  # of the model's metrics at each epoch. \n","  epochs = history.epoch\n","  hist = pd.DataFrame(history.history)\n","\n","  return epochs, hist"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# The following variables are the hyperparameters.\n","learning_rate = 0.003\n","epochs = 60\n","batch_size = 4000\n","validation_split = 0.2\n","\n","# Establish the model's topography.\n","my_model = create_model(learning_rate)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["my_model.summary()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Train the model on the normalized training set.\n","epochs, hist = train_model(my_model, X_train_normalized, Y_train, \n","                           epochs, batch_size, validation_split)\n","\n","# Plot a graph of the metric vs. epochs.\n","list_of_metrics_to_plot = ['accuracy', 'val_accuracy']\n","plot_curve(epochs, hist, list_of_metrics_to_plot)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Predict on test data\n","predictions = np.argmax(my_model.predict(X_test_normalized), axis=1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# write predictions to csv\n","example_indices = np.reshape(np.arange(1,predictions.size+1),(-1,1))\n","headers = np.array([['ImageId', 'Label']])\n","predictions_table = np.concatenate((headers, np.concatenate((example_indices, np.reshape(predictions, (-1,1))), axis=1)), axis=0)\n","\n","np.savetxt('predictions.csv', predictions_table, delimiter=',', fmt='%s')"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}